<!doctype html><!-- begin: layouts/_default/baseof.html --><html lang=en><!-- begin: layouts/partials/head.html --><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.100.1"><title>Adversarial Attacks on RL Agents - weeeblog</title><link rel=icon type=image/svg href=/static/favicon.png><link rel=stylesheet type=text/css href=/main.css><link rel=canonical href=https://nikhilweee.me/blog/2021/adversarial-attacks-deep-rl/><link rel=stylesheet type=text/css href=/hugo-cite.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css integrity=sha384-KiWOvVjnN8qwAZbuQyWDIbfCLFhLXNETzBQjA/92pIowpC0d2O3nppDGQVgwd2nB crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js integrity=sha384-0fdwu/T/EQMsQlrHCCHoH10pkPLlKA1jL5dFyUOvB3lfeT2540/2g6YgSi2BL14p crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1,strict:!1})})</script><link href=https://cdn.jsdelivr.net/npm/charter-webfont/charter.min.css rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css></head><!-- end: layouts/partials/head.html --><body class=flex-parent><div class="sidebar sidebar-left"></div><main class=flex-content><!-- begin: layouts/partials/header.html --><div class=wrapper><header class=site-header><nav class=site-title><a href=/blog><strong>weeeblog</strong></a></nav><nav class=site-nav><a href=/>About</a>
<a href=/blog/>Blog</a>
<a href=/blog/archives>Archives</a></nav><nav class=site-toggle><a id=theme-toggle><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></a></nav></header></div><!-- end: layouts/partials/header.html --><div class="page-content wrapper"><!-- begin: layouts/_default/single.html --><article class=post itemscope itemtype=http://schema.org/BlogPosting><header class=post-header><h1 class=post-title itemprop="name headline">Adversarial Attacks on RL Agents</h1><p class=post-subtitle itemprop="abstract description">using natural observations</p><p class=post-meta><time datetime="2021-12-18 00:00:00 +0000 UTC" itemprop=datePublished>Published Dec 18, 2021</time>
• <time datetime="2021-12-18 00:00:00 +0000 UTC" itemprop=datePublished>Updated Apr 20, 2022</time><br><a href=/blog/archives/long-posts/>Long Posts</a></p></header><div class=post-content itemprop=articleBody><blockquote><p>This post a write up for the final project as part of NYU&rsquo;s graduate course on Deep Reinforcement Learning. The project was the result of a collaboration with <a href=https://in.linkedin.com/in/advika-sumana-reddy>Advika Reddy</a>.</p></blockquote><div class=post-toc><h3>Outline</h3><nav id=TableOfContents><ul><li><a href=#abstract>Abstract</a></li><li><a href=#background>Background</a><ul><li><a href=#what-are-adversarial-attacks>What are Adversarial Attacks?</a></li><li><a href=#how-are-they-different-for-rl-agents>How are they different for RL Agents?</a></li><li><a href=#types-of-adversarial-attacks>Types of Adversarial Attacks</a><ul><li><a href=#white-box-attacks>White-box Attacks</a></li><li><a href=#black-box-attacks>Black-box Attacks</a></li></ul></li></ul></li><li><a href=#motivation>Motivation</a><ul><li><a href=#how-do-the-adversarial-policies-exploit-the-victim>How do the adversarial policies exploit the victim?</a></li><li><a href=#why-are-the-victim-observations-adversarial>Why are the victim observations adversarial?</a></li></ul></li><li><a href=#our-work>Our work</a></li><li><a href=#environment>Environment</a><ul><li><a href=#observation-and-action-spaces>Observation and Action Spaces</a></li><li><a href=#observation-masking>Observation Masking</a></li></ul></li><li><a href=#self-play>Self-Play</a></li><li><a href=#adversarial-training>Adversarial Training</a></li><li><a href=#experiments>Experiments</a><ul><li><a href=#state-based-observations-1m-steps>State Based Observations, 1M steps</a></li><li><a href=#state-based-observations-4m-steps>State Based Observations, 4M steps</a></li><li><a href=#state-based-observations-with-masking-1m-steps>State Based Observations with Masking, 1M steps</a></li><li><a href=#state-based-observations-with-masking-4m-steps>State Based Observations with Masking, 4M steps</a></li><li><a href=#image-based-observations>Image Based Observations</a></li><li><a href=#image-based-observations-with-masking>Image Based Observations (with masking)</a></li></ul></li><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#acknowledgements>Acknowledgements</a></li><li><a href=#references>References</a></li></ul></nav></div><h1 id=abstract>Abstract</h1><hr><p>Prior work
<span class=hugo-cite-intext itemprop=citation>(<span class=hugo-cite-group><a href=#huang2017adversarial><span class=visually-hidden>Citation:&nbsp;</span><span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Sandy"><span itemprop=familyName>Huang</span></span>
<em>et. al.</em>, <span itemprop=datePublished>2017</span></a><span class=hugo-cite-citation>
<span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Huang</span>, <meta itemprop=givenName content="Sandy">Sandy</span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Nicolas">Nicolas 
<span itemprop=familyName>Papernot</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Ian">Ian 
<span itemprop=familyName>Goodfellow</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Yan">Yan 
<span itemprop=familyName>Duan</span></span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Pieter">Pieter 
<span itemprop=familyName>Abbeel</span></span>
 
(<span itemprop=datePublished>2017</span>).
 <span itemprop=name><b><i>Adversarial Attacks on Neural Network Policies.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1702.02284</span>. 
<a href=https://arxiv.org/abs/1702.02284 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1702.02284</a></span>
</span></span>; <span class=hugo-cite-group><a href=#kos2017delving><span class=visually-hidden>Citation:&nbsp;</span><span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Jernej"><span itemprop=familyName>Kos</span></span>
<em>et. al.</em>, <span itemprop=datePublished>2017</span></a><span class=hugo-cite-citation>
<span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Kos</span>, <meta itemprop=givenName content="Jernej">Jernej</span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Dawn">Dawn 
<span itemprop=familyName>Song</span></span>
 
(<span itemprop=datePublished>2017</span>).
 <span itemprop=name><b><i>Delving Into Adversarial Attacks on Deep Policies.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1705.06452</span>. 
<a href=https://arxiv.org/abs/1705.06452 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1705.06452</a></span>
</span></span>)</span> has shown that deep RL policies are vulnerable to small adversarial perturbations to their observations, similar to adversarial examples 
<span class=hugo-cite-intext itemprop=citation>(<span class=hugo-cite-group><a href=#szegedy2013intriguing><span class=visually-hidden>Citation:&nbsp;</span><span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Christian"><span itemprop=familyName>Szegedy</span></span>
<em>et. al.</em>, <span itemprop=datePublished>2013</span></a><span class=hugo-cite-citation>
<span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Szegedy</span>, <meta itemprop=givenName content="Christian">Christian</span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Wojciech">Wojciech 
<span itemprop=familyName>Zaremba</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Ilya">Ilya 
<span itemprop=familyName>Sutskever</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Joan">Joan 
<span itemprop=familyName>Bruna</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Dumitru">Dumitru 
<span itemprop=familyName>Erhan</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Ian">Ian 
<span itemprop=familyName>Goodfellow</span></span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Rob">Rob 
<span itemprop=familyName>Fergus</span></span>
 
(<span itemprop=datePublished>2013</span>).
 <span itemprop=name><b><i>Intriguing properties of Neural Networks.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1312.6199</span>. 
<a href=https://arxiv.org/abs/1312.6199 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1312.6199</a></span>
</span></span>)</span> in image classifiers. Such adversarial models assume that the attacker can directly modify the victim’s observation. However, such attacks are not practical in the real world. In contrast, we look at attacks via adversarial policy designed specifically for the two-agent zero-sum environments. The goal of the attacker is to fail a well-trained agent in the game by manipulating the opponent’s behavior. Specifically, we explore the attacks using an adversarial policy in low-dimensional environments.</p><h1 id=background>Background</h1><hr><h2 id=what-are-adversarial-attacks>What are Adversarial Attacks?</h2><p>An adversarial attack is a method to generate adversarial examples. In a classification system, an adversarial example is an input to a machine learning model that is designed to cause the model to make a mistake in its predictions. The adversarial example is created by adding specific perturbations to an input such that the perturbation is imperceptible to the human eye. Without the perturbation, the input would have been correctly classified. The following image from
<span class=hugo-cite-intext itemprop=citation><span class=hugo-cite-group><a href=#goodfellow2014explaining><span class=visually-hidden>Citation:&nbsp;</span><span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Ian J"><span itemprop=familyName>Goodfellow</span></span>
<em>et. al.</em>, <span itemprop=datePublished>(2014)</span></a><span class=hugo-cite-citation>
<span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Goodfellow</span>, <meta itemprop=givenName content="Ian J">Ian J</span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Jonathon">Jonathon 
<span itemprop=familyName>Shlens</span></span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Christian">Christian 
<span itemprop=familyName>Szegedy</span></span>
 
(<span itemprop=datePublished>2014</span>).
 <span itemprop=name><b><i>Explaining and Harnessing Adversarial Examples.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1412.6572</span>. 
<a href=https://arxiv.org/abs/1412.6572 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1412.6572</a></span></span></span></span> shows a representative example.</p><figure><img src=https://i.imgur.com/aLXQUgY.png alt="Fig. 1: The input image $x$, when fed to a classifier, is classified as a panda with 57.7% confidence. However, when a small amount of noise is added, the resultant image is classified as a gibbon with 99.3% confidence."><figcaption><p>Fig. 1: The input image $x$, when fed to a classifier, is classified as a <em>panda</em> with 57.7% confidence. However, when a small amount of noise is added, the resultant image is classified as a <em>gibbon</em> with 99.3% confidence.</p></figcaption></figure><h2 id=how-are-they-different-for-rl-agents>How are they different for RL Agents?</h2><p>Adversarial attacks on deep RL agents are different from those on classification systems:</p><ul><li>First, an RL agent interacts with the environment through a sequence of actions where each action changes the state of the environment. What the agent receives is a sequence of correlated observations. For an episode of $L$ steps, an adversary can determine whether or not to attack the agent at each time step (i.e., there are $2^L$ choices).</li><li>Second, adversaries to deep RL agents have different goals such as reducing the final rewards of agents or malevolently lure agents to dangerous states, which is different from an adversary to a classification system that aims to lower classification accuracies.</li></ul><h2 id=types-of-adversarial-attacks>Types of Adversarial Attacks</h2><p>Adversarial Attacks can be broadly divided into two types:</p><h3 id=white-box-attacks>White-box Attacks</h3><p>Here, the adversary has complete access to the victim&rsquo;s model, including the model architecture, parameters, and the policy. Most white-box attacks are pixel-based, where the adversary perturbs the observation of the victim. Other forms of attacks target the vulnerabilities of the neural networks. Some popular white-box attacks are listed below:</p><ul><li><em>Fast Gradient Sign Method (FGSM)</em>: FGSM generates adversarial examples to minimize the maximum amount of perturbation added to any pixel of the image to cause misclassification. It is a uniform attack as the adversary attacks at every time step in an episode.</li><li><em>Limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS)</em>: L-BFGS is a non-linear gradient-based numerical optimization algorithm that aims at minimizing the number of perturbations added to images.</li><li><em>Carlini & Wagner Attack (C&W)</em>: C&W is based on the L-BFGS attack but without box constraints and different objective functions, which makes this method more efficient at generating adversarial examples.</li><li><em>Jacobian-based Saliency Map Attack (JSMA)</em>: JSMA uses feature selection to minimize the number of features modified while causing misclassification. Flat perturbations are added to features iteratively according to saliency value by decreasing order.</li></ul><h3 id=black-box-attacks>Black-box Attacks</h3><p>Here, the adversary has limited or no access to the victim model and can only observe the outputs of the victim. A practical assumption here is that the adversary has access to the victim’s observations and actions which it can get from the environment. Some popular attacks are:</p><ul><li><em>Strategically-Timed Attack (STA)</em>: STA accounts for the minimal total temporal perturbation of the input state. The adversary attacks only in critical situations where the victim has a very high probability of taking a particular action.</li><li><em>Enchanting Attack</em>: This attack is based on the sequential property in RL, where the current action affects the next state and so on. It lures the agent to a particular state of the adversary’s choice. This is accomplished by using a planning algorithm (to plan the sequence of actions that would ultimately lead the agent to the target state) and a Deep Generative model (for simulation and predicting the model).</li><li><em>Attacks using Adversarial Policy</em>: This type of attack was introduced recently. The attacker trains an adversarial policy which takes certain actions that generate natural observations that are adversarial to the victim.</li></ul><h1 id=motivation>Motivation</h1><hr><p><span class=hugo-cite-intext itemprop=citation><span class=hugo-cite-group><a href=#gleave2019adversarial><span class=visually-hidden>Citation:&nbsp;</span><span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Adam"><span itemprop=familyName>Gleave</span></span>
<em>et. al.</em>, <span itemprop=datePublished>(2019)</span></a><span class=hugo-cite-citation>
<span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Gleave</span>, <meta itemprop=givenName content="Adam">Adam</span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Michael">Michael 
<span itemprop=familyName>Dennis</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Cody">Cody 
<span itemprop=familyName>Wild</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Neel">Neel 
<span itemprop=familyName>Kant</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Sergey">Sergey 
<span itemprop=familyName>Levine</span></span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Stuart">Stuart 
<span itemprop=familyName>Russell</span></span>
 
(<span itemprop=datePublished>2019</span>).
 <span itemprop=name><b><i>Adversarial Policies: Attacking Deep Reinforcement Learning.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1905.10615</span>. 
<a href=https://arxiv.org/abs/1905.10615 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1905.10615</a></span></span></span></span> demonstrated the existence of adversarial policies in two-agent zero-sum games between simulated humanoid robots against state-of-the-art victims trained via self-play. The adversary wins against the victims by generating seemingly random and uncoordinated behavior, not by becoming a stronger opponent. For instance, in Kick and Defend and You Shall Not Pass, the adversary never stands up but instead learns to lie down in contorted positions on the ground. This confuses the victim and forces it to take wrong actions.</p><h2 id=how-do-the-adversarial-policies-exploit-the-victim>How do the adversarial policies exploit the victim?</h2><p>To better understand how the adversarial policies exploit their victims, the authors created “masked” versions of victim policies. A masked victim observes a static value for the opponent position, corresponding to a typical initial starting state. The authors found that masked victims lost frequently against normal opponents. However, they were robust to adversarial attacks, which shows that the adversary succeeds by naturally manipulating a victim’s observations through its actions. This method is unlike previous works
<span class=hugo-cite-intext itemprop=citation>(<span class=hugo-cite-group><a href=#huang2017adversarial><span class=visually-hidden>Citation:&nbsp;</span><span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Sandy"><span itemprop=familyName>Huang</span></span>
<em>et. al.</em>, <span itemprop=datePublished>2017</span></a><span class=hugo-cite-citation>
<span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Huang</span>, <meta itemprop=givenName content="Sandy">Sandy</span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Nicolas">Nicolas 
<span itemprop=familyName>Papernot</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Ian">Ian 
<span itemprop=familyName>Goodfellow</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Yan">Yan 
<span itemprop=familyName>Duan</span></span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Pieter">Pieter 
<span itemprop=familyName>Abbeel</span></span>
 
(<span itemprop=datePublished>2017</span>).
 <span itemprop=name><b><i>Adversarial Attacks on Neural Network Policies.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1702.02284</span>. 
<a href=https://arxiv.org/abs/1702.02284 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1702.02284</a></span>
</span></span>; <span class=hugo-cite-group><a href=#kos2017delving><span class=visually-hidden>Citation:&nbsp;</span><span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Jernej"><span itemprop=familyName>Kos</span></span>
<em>et. al.</em>, <span itemprop=datePublished>2017</span></a><span class=hugo-cite-citation>
<span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Kos</span>, <meta itemprop=givenName content="Jernej">Jernej</span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Dawn">Dawn 
<span itemprop=familyName>Song</span></span>
 
(<span itemprop=datePublished>2017</span>).
 <span itemprop=name><b><i>Delving Into Adversarial Attacks on Deep Policies.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1705.06452</span>. 
<a href=https://arxiv.org/abs/1705.06452 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1705.06452</a></span>
</span></span>)</span> in adversarial RL literature where the image observations are manipulated directly. The following videos from
<span class=hugo-cite-intext itemprop=citation><span class=hugo-cite-group><a href=#gleave2019adversarial><span class=visually-hidden>Citation:&nbsp;</span><span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Adam"><span itemprop=familyName>Gleave</span></span>
<em>et. al.</em>, <span itemprop=datePublished>(2019)</span></a><span class=hugo-cite-citation>
<span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Gleave</span>, <meta itemprop=givenName content="Adam">Adam</span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Michael">Michael 
<span itemprop=familyName>Dennis</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Cody">Cody 
<span itemprop=familyName>Wild</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Neel">Neel 
<span itemprop=familyName>Kant</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Sergey">Sergey 
<span itemprop=familyName>Levine</span></span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Stuart">Stuart 
<span itemprop=familyName>Russell</span></span>
 
(<span itemprop=datePublished>2019</span>).
 <span itemprop=name><b><i>Adversarial Policies: Attacking Deep Reinforcement Learning.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1905.10615</span>. 
<a href=https://arxiv.org/abs/1905.10615 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1905.10615</a></span></span></span></span> help demonstrate these attacks:</p><figure><video src=https://adversarial-policies-public.s3.amazonaws.com/videos/KickAndDefend-v0_victim_ZooV2_opponent_ZooO2_1080p.mp4 controls></video><figcaption>Fig. 2: Kick and Defend: Normal opponent vs Normal agent<br>The agent is able to kick the ball past the opponent, which tries to block the agent.</figcaption></figure><figure><video src=https://adversarial-policies-public.s3.amazonaws.com/videos/KickAndDefend-v0_victim_ZooV2_opponent_Adv2_1080p.mp4 controls></video><figcaption>Fig 3: Kick and Defend: Adversarial opponent vs Normal agent<br>The opponent discovers new ways to manipulate the agent, which fails to kick the ball. Notice how the opponent isn't "fighting" the agent - it's merely lying on the ground.</figcaption></figure><h2 id=why-are-the-victim-observations-adversarial>Why are the victim observations adversarial?</h2><p>The authors plotted the activations of the victim policy using <a href=https://towardsdatascience.com/gaussian-mixture-models-explained-6986aaf5a95>Gaussian Mixture Models</a> (GMMs) and <a href=http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf>t-SNE</a> visualizations. They observe that the activations induced by an adversarial policy substantially differ from the ones induced by normal opponents. This can be seen by GMM plots which showed high negative mean log probabilities for the victim against an adversarial policy.</p><figure><img src=https://i.imgur.com/6R2fY0C.png alt="Fig. 4: The mean log probabilities of activations induced by adversarial opponents (Adv) are much lower than the activations induced by any other opponent, suggesting that the adversarial observations are different." width=75%><figcaption><p>Fig. 4: The mean log probabilities of activations induced by adversarial opponents (Adv) are much lower than the activations induced by any other opponent, suggesting that the adversarial observations are different.</p></figcaption></figure><p>Although the empirical results are compelling, the reason behind these attacks and the seeming vulnerabilities of the agent policies are still unclear.</p><h1 id=our-work>Our work</h1><p>We’d like to know if the adversarial attacks using natural observations
<span class=hugo-cite-intext itemprop=citation>(<span class=hugo-cite-group><a href=#gleave2019adversarial><span class=visually-hidden>Citation:&nbsp;</span><span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Adam"><span itemprop=familyName>Gleave</span></span>
<em>et. al.</em>, <span itemprop=datePublished>2019</span></a><span class=hugo-cite-citation>
<span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Gleave</span>, <meta itemprop=givenName content="Adam">Adam</span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Michael">Michael 
<span itemprop=familyName>Dennis</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Cody">Cody 
<span itemprop=familyName>Wild</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Neel">Neel 
<span itemprop=familyName>Kant</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Sergey">Sergey 
<span itemprop=familyName>Levine</span></span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Stuart">Stuart 
<span itemprop=familyName>Russell</span></span>
 
(<span itemprop=datePublished>2019</span>).
 <span itemprop=name><b><i>Adversarial Policies: Attacking Deep Reinforcement Learning.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1905.10615</span>. 
<a href=https://arxiv.org/abs/1905.10615 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1905.10615</a></span>
</span></span>)</span> are effective in a low dimensional environment. Our work is focused on a two-player zero-sum game (Pong).</p><p>We first trained a victim policy through self-play using DQN because DQN tends to be more vulnerable to adversarial attacks as opposed to policy gradient methods like PPO and A3C.</p><p>Then, we trained adversarial policies against a fixed victim policy using PPO. We train using both, state based and image based observations.</p><h1 id=environment>Environment</h1><hr><p>We perform experiments on the <code>PongDuel-v0</code> environment from <a href=https://github.com/koulanurag/ma-gym>ma-gym</a>, which is a multi-agent version of the <code>Pong-v0</code> environment from <a href=https://github.com/openai/gym>gym</a>. Unlike <code>Pong-v0</code> where the opponent is a computer, in <code>PongDuel-v0</code>, both players can be controlled independently through different policies. We modify the rendering function to show a scoreboard containing scores of both players, the total number of steps elapsed, and the total number of rounds played so far. Here is what a snapshot of the environment looks like.</p><div style=text-align:center><figure id=fig-5 style=display:inline-block;width:45%><img src=https://i.imgur.com/lDSCYEt.gif><figcaption>Fig. 5: Agents playing PongDuel-v0: State-based observations</figcaption></figure><figure id=fig-6 style=display:inline-block;width:45%><img src=https://i.imgur.com/T25l2bM.gif><figcaption>Fig. 6: Agents playing PongDuel-v0: Image-based observations</figcaption></figure></div><h2 id=observation-and-action-spaces>Observation and Action Spaces</h2><p>Like <a href=https://github.com/openai/gym>gym</a>, <code>PongDuel-v0</code> can either take image-based or state based observations. In case of state-based observations, the observation is a 12 dimensional vector <code>[x_p1, y_p1, x_ball, y_ball, one_hot_ball_dir[6], x_p2, y_p2]</code> containing the x and y coordinates of the agent, ball, and the opponent. Dimensions 5-10 represent one of the six ball directions in one-hot form.</p><p>In case of image based observations, both agents see a 40x30x3 dimensional image created using the observation vector. The grid looks just like the GIFs above, except without the border on the edges and the scoreboard on the top. The action spaces in both cases is 3 dimensional, with each dimension indicating whether the pedal should go up, down, or stay in place.</p><h2 id=observation-masking>Observation Masking</h2><p>Observation masking is when instead of the actual position <code>[x_p2, y_p2]</code> of the opponent, the agent observes a dummy position corresponding to some initial starting value.</p><blockquote><p><strong>A Note on Naming Conventions</strong><br>Throughout our experiments, we use the term <em>agent</em> or <em>victim</em> interchangably to denote the red player. Similarly, we use the terms <em>opponent</em> or <em>adversary</em> interchangably for the blue player.</p></blockquote><h1 id=self-play>Self-Play</h1><hr><p>To perform adversarial training, we first need victim policies to train the adversaries against. We do so by training agents through self-play using DQN. For state-based observations, it was sufficient to train the agents for 1.5M frames. Towards the end of training, the models easily cross an average frame rate of 100 frames per episode. <a href=#fig-5>Fig. 5</a> shows a GIF of two agents playing against each other. Both agents use the same policy, which is the end result of this training.</p><figure><img src=https://i.imgur.com/a6h9Rm7.png alt="Fig. 7: Average frames/ep vs total frames during state-based training. The model crosses ~100 frames/ep."><figcaption><p>Fig. 7: Average frames/ep vs total frames during state-based training. The model crosses ~100 frames/ep.</p></figcaption></figure><p>For image based observations, however, we had to train the model for more than 3.5M frames. Even then, the models were only able to reach an average frame rate of around 50 frames per episode. This is understandable, as there is a dimensionality increase by a factor of 300. Both agents in <a href=#fig-6>Fig. 6</a> use the same policy, which was obtained through image-based training.</p><figure><img src=https://i.imgur.com/RPIzC45.png alt="Fig. 8: Average frames/ep vs total frames during image-based training. The model reaches ~50 frames/ep."><figcaption><p>Fig. 8: Average frames/ep vs total frames during image-based training. The model reaches ~50 frames/ep.</p></figcaption></figure><h1 id=adversarial-training>Adversarial Training</h1><hr><p>Once we have victim policies trained through self-play, we train adversarial policies using the approach mentioned in
<span class=hugo-cite-intext itemprop=citation><span class=hugo-cite-group><a href=#gleave2019adversarial><span class=visually-hidden>Citation:&nbsp;</span><span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Adam"><span itemprop=familyName>Gleave</span></span>
<em>et. al.</em>, <span itemprop=datePublished>(2019)</span></a><span class=hugo-cite-citation>
<span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Gleave</span>, <meta itemprop=givenName content="Adam">Adam</span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Michael">Michael 
<span itemprop=familyName>Dennis</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Cody">Cody 
<span itemprop=familyName>Wild</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Neel">Neel 
<span itemprop=familyName>Kant</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Sergey">Sergey 
<span itemprop=familyName>Levine</span></span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Stuart">Stuart 
<span itemprop=familyName>Russell</span></span>
 
(<span itemprop=datePublished>2019</span>).
 <span itemprop=name><b><i>Adversarial Policies: Attacking Deep Reinforcement Learning.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1905.10615</span>. 
<a href=https://arxiv.org/abs/1905.10615 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1905.10615</a></span>
</span></span></span>. For both types of observations, we train agents using PPO from <a href=https://github.com/DLR-RM/stable-baselines3>stable-baselines3</a>. The opponent is a victim whose policy is stationary.</p><h1 id=experiments>Experiments</h1><p>For each set of results, we run a tournament of 50 games of 20 rounds each. The results for various scenarios are presented in the following sections.</p><h2 id=state-based-observations-1m-steps>State Based Observations, 1M steps</h2><figure><img src=https://i.imgur.com/4PqRjS7.png alt="Fig. 9: Average frames/ep vs total frames for the adversary trained on state-based observations."><figcaption><p>Fig. 9: Average frames/ep vs total frames for the adversary trained on state-based observations.</p></figcaption></figure><p>When the victim plays against an adversary trained for 1M steps, 49 games are won by the victim and one game ends in a draw. Here is a video of games 5 and 11, where the difference between the victim (red) and the adversary (blue) was the lowest (0) and highest (16) respectively. The average score of the victim was 15.26, and the average score of the adversary was 4.74.</p><p>This result is contrary to the one shown by the authors. So what’s the issue here?</p><div style=text-align:center><figure style=display:inline-block;width:45%;vertical-align:top><img src=https://i.imgur.com/sqtxD4K.gif><figcaption>Game 5: The game results in a draw</figcaption></figure><figure style=display:inline-block;width:45%;vertical-align:top><img src=https://i.imgur.com/ku9iLw5.gif><figcaption>Game 11: The victim wins 18-2</figcaption></figure></div><details><summary><strong>Raw Scores for this Tournament</strong></summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># rewards is a list of [victim_score, adversary_score] pairs</span>
</span></span><span class=line><span class=cl><span class=n>rewards</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>]]</span>
</span></span></code></pre></div></details><figure><img src=https://i.imgur.com/olZgwSr.png alt="State-based Observations: Victim vs Adversary for 50 games of 20 rounds each. The victim won 49 games, and 1 game ended in a draw."><figcaption><p>State-based Observations: Victim vs Adversary for 50 games of 20 rounds each. The victim won 49 games, and 1 game ended in a draw.</p></figcaption></figure><h2 id=state-based-observations-4m-steps>State Based Observations, 4M steps</h2><figure><img src=https://i.imgur.com/lX6hb4f.png alt="Instead of 1M steps, the adversary is now trained for 4M steps. We use the best model saved around 3.4M steps."><figcaption><p>Instead of 1M steps, the adversary is now trained for 4M steps. We use the best model saved around 3.4M steps.</p></figcaption></figure><p>On training the adversary for about 3.4M steps, we observe a role reversal. The adversary now wins 48 out of 50 games.</p><div style=text-align:center><figure style=display:inline-block;width:45%;vertical-align:top><img src=https://i.imgur.com/e4tkI3s.gif><figcaption>Game 3: Agent loses 2-18</figcaption></figure><figure style=display:inline-block;width:45%;vertical-align:top><img src=https://i.imgur.com/qQN6wdY.gif><figcaption>Game 10: The game results in a draw</figcaption></figure></div><details><summary><strong>Raw Scores for this Tournament</strong></summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># rewards is a list of [victim_score, adversary_score] pairs</span>
</span></span><span class=line><span class=cl><span class=n>rewards</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>18</span><span class=p>],</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>18</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>20</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>18</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>]]</span>
</span></span></code></pre></div></details><figure><img src=https://i.imgur.com/nv5OPWc.png alt="State-based Observations: Victim vs Adversary for 50 games of 20 rounds each. The victim won 1 game, the adversary won 48 games, and 1 game ended in a draw."><figcaption><p>State-based Observations: Victim vs Adversary for 50 games of 20 rounds each. The victim won 1 game, the adversary won 48 games, and 1 game ended in a draw.</p></figcaption></figure><h2 id=state-based-observations-with-masking-1m-steps>State Based Observations with Masking, 1M steps</h2><p>In order to show that the adversary attacks the agent by inducing natural observations which are adversarial in nature, the authors perform <a href=https://www.notion.so/Adversarial-Attacks-on-RL-Agents-using-Natural-Observations-ab8a7e6bd7494d16988777b882d78d4b>observation masking</a>. If the agent is able to recover during observation masking, it must have been the position of the agent which was inducing erroneous behaviour in the victim. We perform an experiment where we mask the observation of the opponent for both agents. It is evident that both the victim and the adversary’s policies are very much dependent on the other player’s position instead of the kinematics of the ball.</p><div style=text-align:center><figure style=display:inline-block;width:30%;vertical-align:top><img src=https://i.imgur.com/07NWjKz.gif><figcaption>Both players’ observations are masked</figcaption></figure><figure style=display:inline-block;width:30%;vertical-align:top><img src=https://i.imgur.com/3tMaFId.gif><figcaption>Only agent’s observations are masked</figcaption></figure><figure style=display:inline-block;width:30%;vertical-align:top><img src=https://i.imgur.com/YxfBEMj.gif><figcaption>Only opponent’s observations are masked</figcaption></figure></div><details><summary><strong>Raw Scores for this Tournament</strong></summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># rewards is a list of [victim_score, adversary_score] pairs</span>
</span></span><span class=line><span class=cl><span class=c1># Both, the agent and opponent&#39;s observations are masked</span>
</span></span><span class=line><span class=cl><span class=c1># total = [13, 29], average = [9.14, 10.86]</span>
</span></span><span class=line><span class=cl><span class=n>rewards</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=c1># Just the agent&#39;s observations are masked</span>
</span></span><span class=line><span class=cl><span class=c1># total = [9, 30], average = [8.54, 11.46]</span>
</span></span><span class=line><span class=cl><span class=n>rewards</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=c1># Just the opponent&#39;s observations are masked</span>
</span></span><span class=line><span class=cl><span class=c1># total = [50, 0], average = [16.06, 3.94]</span>
</span></span><span class=line><span class=cl><span class=n>rewards</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>19</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>19</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>]]</span>
</span></span></code></pre></div></details><figure><img src=https://i.imgur.com/Q6T0tfS.png alt="State-based Observations with Masking: Victim vs Adversary for 50 games of 20 rounds each. Both agents’ observations were masked. The victim won 13 games, adversary won 29 games, and 8 games ended in a tie."><figcaption><p>State-based Observations with Masking: Victim vs Adversary for 50 games of 20 rounds each. Both agents’ observations were masked. The victim won 13 games, adversary won 29 games, and 8 games ended in a tie.</p></figcaption></figure><h2 id=state-based-observations-with-masking-4m-steps>State Based Observations with Masking, 4M steps</h2><p>When we use the best model from longer training 4M steps, we again see different results. The adversary, which outperformed the victim during full observations, has now lost its advantage. On close investigation, we see that both players are still heavily dependent on the other player’s position to take an appropriate action. Only when the other player fails to take an action does the policy pay attention to the position and velocity of the ball.</p><div style=text-align:center><figure style=display:inline-block;width:30%;vertical-align:top><img src=https://i.imgur.com/g1dTKhF.gif><figcaption>Game 7: Both players’ observations masked</figcaption></figure><figure style=display:inline-block;width:30%;vertical-align:top><img src=https://i.imgur.com/5YEMntn.gif><figcaption>Game 3: Only agent’s observations masked</figcaption></figure><figure style=display:inline-block;width:30%;vertical-align:top><img src=https://i.imgur.com/WEE4GG8.gif><figcaption>Game 1: Only opponent’s observations masked</figcaption></figure></div><details><summary><strong>Raw Scores for this Tournament</strong></summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># rewards is a list of [victim_score, adversary_score] pairs</span>
</span></span><span class=line><span class=cl><span class=c1># Both, the agent and opponent&#39;s observations are masked</span>
</span></span><span class=line><span class=cl><span class=c1># total = [13, 28], average = [9.5, 10.5]</span>
</span></span><span class=line><span class=cl><span class=n>rewards</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=c1># Just the agent&#39;s observations are masked</span>
</span></span><span class=line><span class=cl><span class=c1># total = [0, 50], average = [4.12, 15.88]</span>
</span></span><span class=line><span class=cl><span class=n>rewards</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>18</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> <span class=p>[</span><span class=mi>1</span><span class=p>,</span> <span class=mi>19</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>20</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>18</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>18</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>18</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>8</span><span class=p>,</span> <span class=mi>12</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> <span class=p>[</span><span class=mi>6</span><span class=p>,</span> <span class=mi>14</span><span class=p>],</span> <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> <span class=p>[</span><span class=mi>7</span><span class=p>,</span> <span class=mi>13</span><span class=p>],</span> <span class=p>[</span><span class=mi>2</span><span class=p>,</span> <span class=mi>18</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>4</span><span class=p>,</span> <span class=mi>16</span><span class=p>],</span> <span class=p>[</span><span class=mi>3</span><span class=p>,</span> <span class=mi>17</span><span class=p>],</span> <span class=p>[</span><span class=mi>5</span><span class=p>,</span> <span class=mi>15</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=c1># Just the opponent&#39;s observations are masked</span>
</span></span><span class=line><span class=cl><span class=c1># total = [50, 0], average = [16.4, 3.6]</span>
</span></span><span class=line><span class=cl><span class=n>rewards</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>19</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>20</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>20</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>]]</span>
</span></span></code></pre></div></details><figure><img src=https://i.imgur.com/mPxvK3Z.png alt="State-based Observations with Masking: Victim vs Adversary for 50 games of 20 rounds each. Both agents’ observations were masked. The victim won 13 games, adversary won 28 games, and 9 games ended in a tie."><figcaption><p>State-based Observations with Masking: Victim vs Adversary for 50 games of 20 rounds each. Both agents’ observations were masked. The victim won 13 games, adversary won 28 games, and 9 games ended in a tie.</p></figcaption></figure><h2 id=image-based-observations>Image Based Observations</h2><p>Just like the previous arrangement, the victim plays against an adversary trained for 1M steps. 48 of the 50 games are won by the victim, and 2 games result in a draw. A video of two games is shown below, where Game 6 resulted in a draw and Game 36 resulted in the maximum gap (16) between the scores of the two players. The average score of the victim was 13.94 and the average score of the adversary was 6.06.</p><div style=text-align:center><figure style=display:inline-block;width:45%;vertical-align:top><img src=https://i.imgur.com/sg45QGU.gif><figcaption>Game 6: The game results in a draw</figcaption></figure><figure style=display:inline-block;width:45%;vertical-align:top><img src=https://i.imgur.com/j0S0Cws.gif><figcaption>Game 36: The victim wins 18-2</figcaption></figure></div><details><summary><strong>Raw Scores for this Tournament</strong></summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>rewards</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>]]</span>
</span></span></code></pre></div></details><figure><img src=https://i.imgur.com/SxsleaE.png alt="Image-based Observations: Victim vs Adversary for 50 games of 20 rounds each. The victim won 48 games, and 2 games resulted in a draw."><figcaption><p>Image-based Observations: Victim vs Adversary for 50 games of 20 rounds each. The victim won 48 games, and 2 games resulted in a draw.</p></figcaption></figure><h2 id=image-based-observations-with-masking>Image Based Observations (with masking)</h2><p>We also perform experiments where the observation space was masked. Unlike state-based observations, image-based observations are more robust to falsified information. This stems from the fact that the observation space is high dimensional, so just a few corrupt dimensions do not have a huge impact on the agents’ policies.</p><div style=text-align:center><figure style=display:inline-block;width:30%;vertical-align:top><img src=https://i.imgur.com/70zh5LF.gif><figcaption>Both players’ observations are masked</figcaption></figure><figure style=display:inline-block;width:30%;vertical-align:top><img src=https://i.imgur.com/H7JEXrx.gif><figcaption>Only agent’s observations are masked</figcaption></figure><figure style=display:inline-block;width:30%;vertical-align:top><img src=https://i.imgur.com/VuvvDA5.gif><figcaption>Only opponent’s observations are masked</figcaption></figure></div><details><summary><strong>Raw Scores for this Tournament</strong></summary><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># rewards is a list of [victim_score, adversary_score] pairs</span>
</span></span><span class=line><span class=cl><span class=c1># Both, the agent and opponent&#39;s observations are masked</span>
</span></span><span class=line><span class=cl><span class=c1># total = [44, 1], average = [14.0, 6.0]</span>
</span></span><span class=line><span class=cl><span class=n>rewards</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=c1># Just the agent&#39;s observations are masked</span>
</span></span><span class=line><span class=cl><span class=c1># total = [48, 0], average = [14.18, 5.82]</span>
</span></span><span class=line><span class=cl><span class=n>rewards</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>]]</span>
</span></span><span class=line><span class=cl><span class=c1># Just the opponent&#39;s observations are masked</span>
</span></span><span class=line><span class=cl><span class=c1># total = [47, 1], average = [13.66, 6.34]</span>
</span></span><span class=line><span class=cl><span class=n>rewards</span> <span class=o>=</span> <span class=p>[[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> <span class=p>[</span><span class=mi>14</span><span class=p>,</span> <span class=mi>6</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>17</span><span class=p>,</span> <span class=mi>3</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>11</span><span class=p>,</span> <span class=mi>9</span><span class=p>],</span> <span class=p>[</span><span class=mi>18</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>9</span><span class=p>,</span> <span class=mi>11</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>16</span><span class=p>,</span> <span class=mi>4</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>],</span> 
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>],</span> <span class=p>[</span><span class=mi>15</span><span class=p>,</span> <span class=mi>5</span><span class=p>],</span> <span class=p>[</span><span class=mi>13</span><span class=p>,</span> <span class=mi>7</span><span class=p>]]</span>
</span></span></code></pre></div></details><figure><img src=https://i.imgur.com/q6avE7j.png alt="Image-based Observations with Masking: Victim vs Adversary for 50 games of 20 rounds each. Both agents’ observations were masked. The victim won 44 games, adversary won 1 games, and 5 games ended in a tie."><figcaption><p>Image-based Observations with Masking: Victim vs Adversary for 50 games of 20 rounds each. Both agents’ observations were masked. The victim won 44 games, adversary won 1 games, and 5 games ended in a tie.</p></figcaption></figure><h1 id=key-takeaways>Key Takeaways</h1><hr><p>We aim to answer the following questions for low-dimensional environments:</p><ol><li><p><strong>Do the adversarial policies succeed in low dimensional environments?</strong></p><p>In our experiments, the adversary was not able to defeat the victim for state-based observations even though it was trained for a considerable amount of time. This may be because the victim is trained so well that it is really difficult to find flaws in its judgement.</p><p>This result is in accordance with the results of the paper by
<span class=hugo-cite-intext itemprop=citation><span class=hugo-cite-group><a href=#gleave2019adversarial><span class=visually-hidden>Citation:&nbsp;</span><span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Adam"><span itemprop=familyName>Gleave</span></span>
<em>et. al.</em>, <span itemprop=datePublished>(2019)</span></a><span class=hugo-cite-citation>
<span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Gleave</span>, <meta itemprop=givenName content="Adam">Adam</span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Michael">Michael 
<span itemprop=familyName>Dennis</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Cody">Cody 
<span itemprop=familyName>Wild</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Neel">Neel 
<span itemprop=familyName>Kant</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Sergey">Sergey 
<span itemprop=familyName>Levine</span></span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Stuart">Stuart 
<span itemprop=familyName>Russell</span></span>
 
(<span itemprop=datePublished>2019</span>).
 <span itemprop=name><b><i>Adversarial Policies: Attacking Deep Reinforcement Learning.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1905.10615</span>. 
<a href=https://arxiv.org/abs/1905.10615 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1905.10615</a></span>
</span></span></span>. The authors also observe that attacks via adversarial policies are more successful on high-dimensional environments (e.g., Sumo Humans) than on low-dimensional environments (e.g., Sumo Ants).</p></li><li><p><strong>Why are the attacks possible in the first place?</strong></p><p>Although we weren’t able to find adversarial policies in our experiments,
<span class=hugo-cite-intext itemprop=citation><span class=hugo-cite-group><a href=#gleave2019adversarial><span class=visually-hidden>Citation:&nbsp;</span><span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Adam"><span itemprop=familyName>Gleave</span></span>
<em>et. al.</em>, <span itemprop=datePublished>(2019)</span></a><span class=hugo-cite-citation>
<span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Gleave</span>, <meta itemprop=givenName content="Adam">Adam</span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Michael">Michael 
<span itemprop=familyName>Dennis</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Cody">Cody 
<span itemprop=familyName>Wild</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Neel">Neel 
<span itemprop=familyName>Kant</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Sergey">Sergey 
<span itemprop=familyName>Levine</span></span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Stuart">Stuart 
<span itemprop=familyName>Russell</span></span>
 
(<span itemprop=datePublished>2019</span>).
 <span itemprop=name><b><i>Adversarial Policies: Attacking Deep Reinforcement Learning.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1905.10615</span>. 
<a href=https://arxiv.org/abs/1905.10615 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1905.10615</a></span></span></span></span> show that the situation is different in high dimensional environments. If the victim were to play a <a href=https://en.wikipedia.org/wiki/Nash_equilibrium>Nash equilibria</a>, it wouldn’t be exploitable by an adversary. However, the authors focus on attacking victim policies trained through self-play
<span class=hugo-cite-intext itemprop=citation>(<span class=hugo-cite-group><a href=#heinrich2015fictitious><span class=visually-hidden>Citation:&nbsp;</span><span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Johannes"><span itemprop=familyName>Heinrich</span></span>
<em>et. al.</em>, <span itemprop=datePublished>2015</span></a><span class=hugo-cite-citation>
<span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Heinrich</span>, <meta itemprop=givenName content="Johannes">Johannes</span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Marc">Marc 
<span itemprop=familyName>Lanctot</span></span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="David">David 
<span itemprop=familyName>Silver</span></span>
 
(<span itemprop=datePublished>2015</span>).
 <span itemprop=name><b><i>Fictitious Self-Play in Extensive-Form Games.</i></b></span>
<span itemprop=about>International conference on machine learning</span>. 
<a href=https://proceedings.mlr.press/v37/heinrich15.html itemprop=identifier itemtype=https://schema.org/URL>https://proceedings.mlr.press/v37/heinrich15.html</a></span>
</span></span>)</span>, a popular method that approximates local Nash equilibria. Self-play assumes transitivity, and perhaps that is the reason behind its vulnerability to these attacks.</p></li><li><p><strong>Isn’t the adversary just a stronger opponent?</strong></p><p>It’s difficult to differentiate between an adversarial agent and a stronger opponent. However, observation masking seems to be one way to differentiate between the two. If the victim is able to perform better when the adversary’s position is masked, the adversary may be exploiting the victim through its observations.</p></li><li><p><strong>How to protect against adversarial attacks?</strong></p><p>Fine-tuning a victim against a specific adversary is one way to combat such attacks. However, the attack can be successfully reapplied to find a new adversarial policy. This suggests repeated fine-tuning might provide protection against a range of adversaries.</p><p>Another challenge in this approach is that fine-tuning a victim protects it against a specific adversary, but the victim tends to forget how to play against a normal opponent.</p></li></ol><h1 id=conclusion>Conclusion</h1><hr><p>From our observation-masking experiments, we can infer that the state-based policies are still heavily dependent on the opponent’s position to take a suitable action. When this information is flawed, the policies fail. However, when the opponent does not move, the policies have learnt to pay attention to the position and velocity of the ball instead.</p><p>We are tempted to say that it is difficult to induce adversarial observations in low dimensional environments, perhaps because the policy learns to tackle all possible situations in an exhaustive manner. For high dimensional observations, adversarial attacks seem to work.</p><h1 id=acknowledgements>Acknowledgements</h1><hr><p>Our code for this project is heavily derived from <a href=https://github.com/PavelCz/rl-adversarial-attack>rl-adversarial-attack</a>. We would also like to thank our course instructor, <a href=https://www.lerrelpinto.com/>Prof. Lerrel Pinto</a>, and <a href=https://www.linkedin.com/in/nshafiul/>Mahi Shafiullah</a>, our course TA for their helpful insights on this project.</p><h1 id=references>References</h1><hr><section class=hugo-cite-bibliography><dl><div id=gleave2019adversarial><dd><span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Gleave</span>, <meta itemprop=givenName content="Adam">Adam</span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Michael">Michael 
<span itemprop=familyName>Dennis</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Cody">Cody 
<span itemprop=familyName>Wild</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Neel">Neel 
<span itemprop=familyName>Kant</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Sergey">Sergey 
<span itemprop=familyName>Levine</span></span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Stuart">Stuart 
<span itemprop=familyName>Russell</span></span>
 
(<span itemprop=datePublished>2019</span>).
 <span itemprop=name><b><i>Adversarial Policies: Attacking Deep Reinforcement Learning.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1905.10615</span>. 
<a href=https://arxiv.org/abs/1905.10615 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1905.10615</a></span></dd></div><div id=goodfellow2014explaining><dd><span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Goodfellow</span>, <meta itemprop=givenName content="Ian J">Ian J</span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Jonathon">Jonathon 
<span itemprop=familyName>Shlens</span></span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Christian">Christian 
<span itemprop=familyName>Szegedy</span></span>
 
(<span itemprop=datePublished>2014</span>).
 <span itemprop=name><b><i>Explaining and Harnessing Adversarial Examples.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1412.6572</span>. 
<a href=https://arxiv.org/abs/1412.6572 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1412.6572</a></span></dd></div><div id=heinrich2015fictitious><dd><span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Heinrich</span>, <meta itemprop=givenName content="Johannes">Johannes</span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Marc">Marc 
<span itemprop=familyName>Lanctot</span></span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="David">David 
<span itemprop=familyName>Silver</span></span>
 
(<span itemprop=datePublished>2015</span>).
 <span itemprop=name><b><i>Fictitious Self-Play in Extensive-Form Games.</i></b></span>
<span itemprop=about>International conference on machine learning</span>. 
<a href=https://proceedings.mlr.press/v37/heinrich15.html itemprop=identifier itemtype=https://schema.org/URL>https://proceedings.mlr.press/v37/heinrich15.html</a></span></dd></div><div id=huang2017adversarial><dd><span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Huang</span>, <meta itemprop=givenName content="Sandy">Sandy</span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Nicolas">Nicolas 
<span itemprop=familyName>Papernot</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Ian">Ian 
<span itemprop=familyName>Goodfellow</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Yan">Yan 
<span itemprop=familyName>Duan</span></span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Pieter">Pieter 
<span itemprop=familyName>Abbeel</span></span>
 
(<span itemprop=datePublished>2017</span>).
 <span itemprop=name><b><i>Adversarial Attacks on Neural Network Policies.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1702.02284</span>. 
<a href=https://arxiv.org/abs/1702.02284 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1702.02284</a></span></dd></div><div id=kos2017delving><dd><span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Kos</span>, <meta itemprop=givenName content="Jernej">Jernej</span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Dawn">Dawn 
<span itemprop=familyName>Song</span></span>
 
(<span itemprop=datePublished>2017</span>).
 <span itemprop=name><b><i>Delving Into Adversarial Attacks on Deep Policies.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1705.06452</span>. 
<a href=https://arxiv.org/abs/1705.06452 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1705.06452</a></span></dd></div><div id=szegedy2013intriguing><dd><span itemscope itemtype=https://schema.org/Article data-type=article><span itemprop=author itemscope itemtype=https://schema.org/Person><span itemprop=familyName>Szegedy</span>, <meta itemprop=givenName content="Christian">Christian</span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Wojciech">Wojciech 
<span itemprop=familyName>Zaremba</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Ilya">Ilya 
<span itemprop=familyName>Sutskever</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Joan">Joan 
<span itemprop=familyName>Bruna</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Dumitru">Dumitru 
<span itemprop=familyName>Erhan</span></span>, 
<span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Ian">Ian 
<span itemprop=familyName>Goodfellow</span></span> & <span itemprop=author itemscope itemtype=https://schema.org/Person><meta itemprop=givenName content="Rob">Rob 
<span itemprop=familyName>Fergus</span></span>
 
(<span itemprop=datePublished>2013</span>).
 <span itemprop=name><b><i>Intriguing properties of Neural Networks.</i></b></span>
<span itemprop=about>arXiv preprint arXiv:1312.6199</span>. 
<a href=https://arxiv.org/abs/1312.6199 itemprop=identifier itemtype=https://schema.org/URL>https://arxiv.org/abs/1312.6199</a></span></dd></div></dl></section></div></article><!-- end: layouts/_default/single.html --></div><!-- begin: layouts/partials/footer.html --><div class=wrapper><div class=giscus></div></div><footer class=site-footer><div class=wrapper><p>&copy; 2022 <a href=/>Nikhil Verma</a> • Subscribe via <a href=/feed.xml>RSS</a></p></div></footer><!-- end: layouts/partials/footer.html --></main><div class="sidebar sidebar-right"><aside class=sidebar-toc><h1>Outline</h1><nav id=TableOfContents><ul><li><a href=#abstract>Abstract</a></li><li><a href=#background>Background</a><ul><li><a href=#what-are-adversarial-attacks>What are Adversarial Attacks?</a></li><li><a href=#how-are-they-different-for-rl-agents>How are they different for RL Agents?</a></li><li><a href=#types-of-adversarial-attacks>Types of Adversarial Attacks</a><ul><li><a href=#white-box-attacks>White-box Attacks</a></li><li><a href=#black-box-attacks>Black-box Attacks</a></li></ul></li></ul></li><li><a href=#motivation>Motivation</a><ul><li><a href=#how-do-the-adversarial-policies-exploit-the-victim>How do the adversarial policies exploit the victim?</a></li><li><a href=#why-are-the-victim-observations-adversarial>Why are the victim observations adversarial?</a></li></ul></li><li><a href=#our-work>Our work</a></li><li><a href=#environment>Environment</a><ul><li><a href=#observation-and-action-spaces>Observation and Action Spaces</a></li><li><a href=#observation-masking>Observation Masking</a></li></ul></li><li><a href=#self-play>Self-Play</a></li><li><a href=#adversarial-training>Adversarial Training</a></li><li><a href=#experiments>Experiments</a><ul><li><a href=#state-based-observations-1m-steps>State Based Observations, 1M steps</a></li><li><a href=#state-based-observations-4m-steps>State Based Observations, 4M steps</a></li><li><a href=#state-based-observations-with-masking-1m-steps>State Based Observations with Masking, 1M steps</a></li><li><a href=#state-based-observations-with-masking-4m-steps>State Based Observations with Masking, 4M steps</a></li><li><a href=#image-based-observations>Image Based Observations</a></li><li><a href=#image-based-observations-with-masking>Image Based Observations (with masking)</a></li></ul></li><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#conclusion>Conclusion</a></li><li><a href=#acknowledgements>Acknowledgements</a></li><li><a href=#references>References</a></li></ul></nav></aside></div></body><script type=text/javascript>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark'),document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light'),changeGiscusTheme()):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'),changeGiscusTheme())});function changeGiscusTheme(){let t=localStorage.getItem("pref-theme"),n={setConfig:{theme:t}},e=document.querySelector('iframe.giscus-frame');e&&e.contentWindow.postMessage({giscus:n},'https://giscus.app')}function handleMessage(e){if(e.origin!=='https://giscus.app')return;if(typeof e.data!='object'||!e.data.giscus)return;const t=e.data.giscus;changeGiscusTheme()}window.addEventListener('message',handleMessage)</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-0JVB0SEFDJ"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-0JVB0SEFDJ',{anonymize_ip:!1})}</script><script src=https://giscus.app/client.js data-repo=nikhilweee/nikhilweee.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkzOTU5NjUwNTc=" data-category=Comments data-category-id=DIC_kwDOF5nygc4COpdc data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=preferred_color_scheme data-lang=en crossorigin=anonymous async></script><!-- end: layouts/_default/baseof.html --></html>