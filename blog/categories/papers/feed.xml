<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Papers on Nikhil Verma</title><link>https://nikhilweee.github.io/blog/categories/papers/</link><description>Recent content in Papers on Nikhil Verma</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>nikhilweee@gmail.com (Nikhil Verma)</managingEditor><webMaster>nikhilweee@gmail.com (Nikhil Verma)</webMaster><copyright>&amp;copy; Nikhil Verma</copyright><lastBuildDate>Fri, 11 Sep 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://nikhilweee.github.io/blog/categories/papers/feed.xml" rel="self" type="application/rss+xml"/><item><title>Intro to Style Transfer</title><link>https://nikhilweee.github.io/blog/2020/intro-to-style-transfer/</link><pubDate>Fri, 11 Sep 2020 00:00:00 +0000</pubDate><author>nikhilweee@gmail.com (Nikhil Verma)</author><guid>https://nikhilweee.github.io/blog/2020/intro-to-style-transfer/</guid><description>Image Style Transfer Using Convolutional Neural Networks This paper introduced neural style transfer. It uses a VGGNet pre-trained on the ImageNet dataset for the purpose. The key idea is to be able to separate content and style from the representations of the network. Once that is done, a new image is synthesized from white noise where two different kind of losses are minimized - a style loss between the style image and the hybrid image, and a content loss between the content image and the hybrid image.</description></item></channel></rss>